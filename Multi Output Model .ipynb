{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor,MultiOutputClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df = pd.read_csv('train.csv',header=None)\n",
    "y_train1 = df.iloc[:,294:]\n",
    "x_train1= df.iloc[:,:294]\n",
    "\n",
    "#x_train1=x_train1.drop(drop_col_indx,axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( x_train1, y_train1, test_size=0.2, random_state=42)\n",
    "\n",
    "#y_test1= MultiOutputRegressor(GradientBoostingRegressor(min_samples_split=25,learning_rate=0.15,max_depth=4, min_samples_leaf=10,random_state=10,n_estimators=22)).fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#y_test1= MultiOutputRegressor(SVR(C=60,kernel='linear')).fit(X_train, y_train).predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5902777777777778"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svr = Pipeline([('scl', StandardScaler()),\n",
    "        ('reg', MultiOutputRegressor(SVR(C=150,epsilon=0.1)))])\n",
    "\n",
    "pipe_svc = Pipeline([('scl', StandardScaler()),\n",
    "        ('clas', MultiOutputClassifier(SVC(C=100)))])\n",
    "\n",
    "\n",
    "y_test1=pipe_svr.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#For Rounding the Regressor Output to INt\n",
    "y_test1=np.around(y_test1, decimals=0)\n",
    "y_test1=y_test1.astype(np.int64)\n",
    "\n",
    "\n",
    "#Calculating the Accuracy \n",
    "accuracy_score(y_test,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##GridSearch CV FOR MULTIOUTPUT Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhruvrajrawat/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scl',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('reg',\n",
       "                 MultiOutputRegressor(estimator=SVR(C=150, cache_size=200,\n",
       "                                                    coef0=0.0, degree=3,\n",
       "                                                    epsilon=0.1,\n",
       "                                                    gamma='auto_deprecated',\n",
       "                                                    kernel='rbf', max_iter=-1,\n",
       "                                                    shrinking=True, tol=0.001,\n",
       "                                                    verbose=False),\n",
       "                                      n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_svr = Pipeline([('scl', StandardScaler()),\n",
    "        ('reg', MultiOutputRegressor(SVR()))])\n",
    "\n",
    "grid_param_svr = {\n",
    "    'reg__estimator__C': [50,100,150,175,200,250,300],\n",
    "    'reg__estimator__epsilon':[0.1]\n",
    "}\n",
    "\n",
    "gs_svr = (GridSearchCV(estimator=pipe_svr, \n",
    "                      param_grid=grid_param_svr, \n",
    "                      cv=10,\n",
    "                      \n",
    "                      n_jobs = -1))\n",
    "\n",
    "gs_svr = gs_svr.fit(x_train1,y_train1)\n",
    "gs_svr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'scl', 'reg', 'scl__copy', 'scl__with_mean', 'scl__with_std', 'reg__estimator__C', 'reg__estimator__cache_size', 'reg__estimator__coef0', 'reg__estimator__degree', 'reg__estimator__epsilon', 'reg__estimator__gamma', 'reg__estimator__kernel', 'reg__estimator__max_iter', 'reg__estimator__shrinking', 'reg__estimator__tol', 'reg__estimator__verbose', 'reg__estimator', 'reg__n_jobs'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svr.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.74168595e-03, 1.05714061e-04, 4.47237845e-04, 1.88542075e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.38187468e-03,\n",
       "       7.10380809e-04, 1.75349918e-03, 3.66167784e-03, 3.21716985e-03,\n",
       "       2.25133368e-03, 3.51871443e-03, 1.12504393e-02, 6.25346454e-04,\n",
       "       1.89569958e-05, 8.01500456e-04, 4.37944013e-03, 2.25090511e-02,\n",
       "       1.94758288e-02, 1.69307396e-02, 2.44624965e-02, 1.91742423e-02,\n",
       "       4.01106050e-02, 7.43140883e-02, 2.38216901e-02, 1.06523725e-02,\n",
       "       1.67750549e-03, 2.39082441e-03, 8.13265992e-04, 3.15791385e-05,\n",
       "       2.06335716e-03, 1.30913389e-03, 7.74175952e-04, 2.71847868e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.07183599e-03, 2.58502934e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.42590690e-03, 2.94675569e-03, 1.64531257e-04, 7.12012119e-04,\n",
       "       2.06978423e-03, 3.44279619e-01, 3.13942487e-03, 2.53456964e-03,\n",
       "       8.72383638e-02, 8.54563218e-03, 6.82139261e-03, 8.04271818e-03,\n",
       "       6.81829451e-03, 2.86131632e-03, 1.22356291e-04, 2.06159912e-03,\n",
       "       5.59111163e-03, 3.06158594e-05, 9.37800642e-04, 6.77165696e-04,\n",
       "       9.74428271e-04, 0.00000000e+00, 1.16931063e-04, 8.60914542e-04,\n",
       "       3.19495736e-04, 9.44349101e-04, 1.14805199e-03, 0.00000000e+00,\n",
       "       9.76192723e-04, 9.47574448e-04, 3.95222608e-03, 5.57145776e-04,\n",
       "       1.11600013e-03, 0.00000000e+00, 2.63052672e-04, 0.00000000e+00,\n",
       "       3.15598177e-04, 6.17572753e-04, 2.01564224e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.23399120e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.69606256e-04, 1.35005254e-05, 0.00000000e+00,\n",
       "       1.82331033e-04, 9.24551936e-05, 0.00000000e+00, 1.53772097e-05,\n",
       "       0.00000000e+00, 1.66703504e-05, 1.69019522e-05, 7.55188793e-04,\n",
       "       3.35998001e-04, 5.88507278e-05, 7.88363130e-04, 0.00000000e+00,\n",
       "       5.23919372e-04, 1.80790753e-04, 0.00000000e+00, 1.43173315e-04,\n",
       "       1.43160705e-04, 0.00000000e+00, 5.67048347e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.39165220e-03, 1.20359561e-03, 7.77009206e-05,\n",
       "       1.07557133e-04, 0.00000000e+00, 0.00000000e+00, 1.39786256e-04,\n",
       "       3.53752848e-05, 2.37546143e-02, 3.25823082e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.51036753e-04, 7.36492699e-03, 1.00856324e-02,\n",
       "       4.23180189e-04, 5.49301246e-03, 6.76901325e-03, 1.84979883e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.73946632e-05, 1.64027555e-03,\n",
       "       2.58235301e-03, 5.56424174e-03, 8.80496493e-03, 9.86766237e-04,\n",
       "       1.14982754e-03, 6.77597883e-02, 2.83202908e-03, 1.48723048e-04,\n",
       "       2.41806554e-04, 6.42687735e-04, 2.78767446e-04, 3.90191059e-04,\n",
       "       1.34476416e-03, 2.80959882e-03, 8.76905627e-04, 1.14328981e-03,\n",
       "       4.93047964e-03, 0.00000000e+00, 3.98616915e-04, 1.48337819e-05,\n",
       "       1.42208563e-03, 7.90760631e-04, 0.00000000e+00, 1.39868040e-04,\n",
       "       6.68329957e-04, 2.33221745e-04, 4.04657459e-03, 1.32955069e-02,\n",
       "       1.88774140e-05, 0.00000000e+00, 6.66475334e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.27798793e-05])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regr_multi_RF=MultiOutputRegressor(RandomForestRegressor(min_samples_split=20, min_samples_leaf=10,random_state=10,n_estimators=30))\n",
    "regr_multi_RF.fit(x_train1,y_train1)\n",
    "\n",
    "# how many estimators?\n",
    "len(regr_multi_RF.estimators_)\n",
    "# 2\n",
    "\n",
    "regr_multi_RF.estimators_[0].feature_importances_\n",
    "# array([ 0.4,  0.6])\n",
    "\n",
    "regr_multi_RF.estimators_[1].feature_importances_\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_coef = regr_multi_RF.estimators_[0].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col_indx=[]\n",
    "for col,val in enumerate(imp_coef):\n",
    "    if val<0.0001:\n",
    "        drop_col_indx.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 34,\n",
       " 65,\n",
       " 66,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 72,\n",
       " 88,\n",
       " 109,\n",
       " 123,\n",
       " 126,\n",
       " 136,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 150,\n",
       " 151,\n",
       " 153,\n",
       " 158,\n",
       " 159]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_col_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>13</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>21</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>...</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.792806</td>\n",
       "      <td>0.847413</td>\n",
       "      <td>0.744884</td>\n",
       "      <td>0.764534</td>\n",
       "      <td>0.810743</td>\n",
       "      <td>0.838431</td>\n",
       "      <td>0.751858</td>\n",
       "      <td>0.753316</td>\n",
       "      <td>0.849535</td>\n",
       "      <td>0.303032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317461</td>\n",
       "      <td>0.189214</td>\n",
       "      <td>0.269183</td>\n",
       "      <td>0.016788</td>\n",
       "      <td>0.013705</td>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>0.015069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.631642</td>\n",
       "      <td>0.670668</td>\n",
       "      <td>0.677323</td>\n",
       "      <td>0.748249</td>\n",
       "      <td>0.782133</td>\n",
       "      <td>0.611240</td>\n",
       "      <td>0.632528</td>\n",
       "      <td>0.812389</td>\n",
       "      <td>0.637667</td>\n",
       "      <td>0.475344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078913</td>\n",
       "      <td>0.175919</td>\n",
       "      <td>0.223353</td>\n",
       "      <td>0.041061</td>\n",
       "      <td>0.050408</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>0.050673</td>\n",
       "      <td>0.055661</td>\n",
       "      <td>0.079765</td>\n",
       "      <td>0.097522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.982745</td>\n",
       "      <td>0.850750</td>\n",
       "      <td>0.785884</td>\n",
       "      <td>0.922892</td>\n",
       "      <td>0.944247</td>\n",
       "      <td>0.826791</td>\n",
       "      <td>0.720847</td>\n",
       "      <td>0.876573</td>\n",
       "      <td>0.980914</td>\n",
       "      <td>0.794011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209348</td>\n",
       "      <td>0.169218</td>\n",
       "      <td>0.337669</td>\n",
       "      <td>0.083091</td>\n",
       "      <td>0.187438</td>\n",
       "      <td>0.532243</td>\n",
       "      <td>0.232948</td>\n",
       "      <td>0.195177</td>\n",
       "      <td>0.221791</td>\n",
       "      <td>0.201402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.766792</td>\n",
       "      <td>0.610776</td>\n",
       "      <td>0.575085</td>\n",
       "      <td>0.472539</td>\n",
       "      <td>0.442304</td>\n",
       "      <td>0.500253</td>\n",
       "      <td>0.507535</td>\n",
       "      <td>0.405099</td>\n",
       "      <td>0.509126</td>\n",
       "      <td>0.366228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370191</td>\n",
       "      <td>0.084081</td>\n",
       "      <td>0.145852</td>\n",
       "      <td>0.148042</td>\n",
       "      <td>0.211724</td>\n",
       "      <td>0.115635</td>\n",
       "      <td>0.297193</td>\n",
       "      <td>0.254088</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.146297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.685375</td>\n",
       "      <td>0.774313</td>\n",
       "      <td>0.639332</td>\n",
       "      <td>0.592065</td>\n",
       "      <td>0.465693</td>\n",
       "      <td>0.507610</td>\n",
       "      <td>0.520886</td>\n",
       "      <td>0.610026</td>\n",
       "      <td>0.649071</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442008</td>\n",
       "      <td>0.347993</td>\n",
       "      <td>0.256008</td>\n",
       "      <td>0.166874</td>\n",
       "      <td>0.100561</td>\n",
       "      <td>0.157648</td>\n",
       "      <td>0.129825</td>\n",
       "      <td>0.075116</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>0.022725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>0.740936</td>\n",
       "      <td>0.800728</td>\n",
       "      <td>0.798471</td>\n",
       "      <td>0.699458</td>\n",
       "      <td>0.797164</td>\n",
       "      <td>0.757937</td>\n",
       "      <td>0.605701</td>\n",
       "      <td>0.472117</td>\n",
       "      <td>0.277052</td>\n",
       "      <td>0.848281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030961</td>\n",
       "      <td>0.036122</td>\n",
       "      <td>0.075832</td>\n",
       "      <td>0.061080</td>\n",
       "      <td>0.077239</td>\n",
       "      <td>0.038433</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.007776</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>0.037436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>0.640453</td>\n",
       "      <td>0.697983</td>\n",
       "      <td>0.694132</td>\n",
       "      <td>0.687415</td>\n",
       "      <td>0.512566</td>\n",
       "      <td>0.661690</td>\n",
       "      <td>0.700183</td>\n",
       "      <td>0.644097</td>\n",
       "      <td>0.653159</td>\n",
       "      <td>0.457523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140346</td>\n",
       "      <td>0.347075</td>\n",
       "      <td>0.200204</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.009045</td>\n",
       "      <td>0.032089</td>\n",
       "      <td>0.141872</td>\n",
       "      <td>0.010918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>0.802678</td>\n",
       "      <td>0.729252</td>\n",
       "      <td>0.749867</td>\n",
       "      <td>0.782630</td>\n",
       "      <td>0.516204</td>\n",
       "      <td>0.696617</td>\n",
       "      <td>0.723308</td>\n",
       "      <td>0.587297</td>\n",
       "      <td>0.864239</td>\n",
       "      <td>0.379290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058883</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.401406</td>\n",
       "      <td>0.736897</td>\n",
       "      <td>0.172458</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.030422</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0.002626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>0.582376</td>\n",
       "      <td>0.648720</td>\n",
       "      <td>0.613431</td>\n",
       "      <td>0.548195</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>0.815766</td>\n",
       "      <td>0.809939</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>0.754965</td>\n",
       "      <td>0.731211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059576</td>\n",
       "      <td>0.134512</td>\n",
       "      <td>0.057485</td>\n",
       "      <td>0.022966</td>\n",
       "      <td>0.018802</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.116047</td>\n",
       "      <td>0.039915</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.056335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>0.556862</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.488667</td>\n",
       "      <td>0.530536</td>\n",
       "      <td>0.817403</td>\n",
       "      <td>0.575404</td>\n",
       "      <td>0.351877</td>\n",
       "      <td>0.508449</td>\n",
       "      <td>0.626270</td>\n",
       "      <td>0.804005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099486</td>\n",
       "      <td>0.046479</td>\n",
       "      <td>0.059689</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.036774</td>\n",
       "      <td>0.018512</td>\n",
       "      <td>0.014463</td>\n",
       "      <td>0.044270</td>\n",
       "      <td>0.041442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1438 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           13        17        18        19        21        24        25   \\\n",
       "0     0.792806  0.847413  0.744884  0.764534  0.810743  0.838431  0.751858   \n",
       "1     0.631642  0.670668  0.677323  0.748249  0.782133  0.611240  0.632528   \n",
       "2     0.982745  0.850750  0.785884  0.922892  0.944247  0.826791  0.720847   \n",
       "3     0.766792  0.610776  0.575085  0.472539  0.442304  0.500253  0.507535   \n",
       "4     0.685375  0.774313  0.639332  0.592065  0.465693  0.507610  0.520886   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1433  0.740936  0.800728  0.798471  0.699458  0.797164  0.757937  0.605701   \n",
       "1434  0.640453  0.697983  0.694132  0.687415  0.512566  0.661690  0.700183   \n",
       "1435  0.802678  0.729252  0.749867  0.782630  0.516204  0.696617  0.723308   \n",
       "1436  0.582376  0.648720  0.613431  0.548195  0.754202  0.815766  0.809939   \n",
       "1437  0.556862  0.747419  0.488667  0.530536  0.817403  0.575404  0.351877   \n",
       "\n",
       "           26        27        28   ...       284       285       286  \\\n",
       "0     0.753316  0.849535  0.303032  ...  0.317461  0.189214  0.269183   \n",
       "1     0.812389  0.637667  0.475344  ...  0.078913  0.175919  0.223353   \n",
       "2     0.876573  0.980914  0.794011  ...  0.209348  0.169218  0.337669   \n",
       "3     0.405099  0.509126  0.366228  ...  0.370191  0.084081  0.145852   \n",
       "4     0.610026  0.649071  0.377131  ...  0.442008  0.347993  0.256008   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1433  0.472117  0.277052  0.848281  ...  0.030961  0.036122  0.075832   \n",
       "1434  0.644097  0.653159  0.457523  ...  0.140346  0.347075  0.200204   \n",
       "1435  0.587297  0.864239  0.379290  ...  0.058883  0.004463  0.002236   \n",
       "1436  0.798278  0.754965  0.731211  ...  0.059576  0.134512  0.057485   \n",
       "1437  0.508449  0.626270  0.804005  ...  0.099486  0.046479  0.059689   \n",
       "\n",
       "           287       288       289       290       291       292       293  \n",
       "0     0.016788  0.013705  0.012601  0.010687  0.010919  0.011375  0.015069  \n",
       "1     0.041061  0.050408  0.051189  0.050673  0.055661  0.079765  0.097522  \n",
       "2     0.083091  0.187438  0.532243  0.232948  0.195177  0.221791  0.201402  \n",
       "3     0.148042  0.211724  0.115635  0.297193  0.254088  0.221800  0.146297  \n",
       "4     0.166874  0.100561  0.157648  0.129825  0.075116  0.060953  0.022725  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1433  0.061080  0.077239  0.038433  0.016594  0.007776  0.043936  0.037436  \n",
       "1434  0.003339  0.003448  0.002265  0.009045  0.032089  0.141872  0.010918  \n",
       "1435  0.401406  0.736897  0.172458  0.003192  0.030422  0.004995  0.002626  \n",
       "1436  0.022966  0.018802  0.040643  0.116047  0.039915  0.075365  0.056335  \n",
       "1437  0.007185  0.013072  0.036774  0.018512  0.014463  0.044270  0.041442  \n",
       "\n",
       "[1438 rows x 170 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1.drop(drop_col_indx,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test= pd.DataFrame(data=y_test)\n",
    "#np.savetxt(\"foo.csv\", y_test, delimiter=\",\")\n",
    "\n",
    "df_test.to_csv('prediction.csv',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
